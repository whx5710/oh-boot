# Tomcat
server:
  tomcat:
    uri-encoding: UTF-8
    threads:
      max: 1000
      min-spare: 30
  port: 8080
  servlet:
    context-path: /
    session.cookie.http-only: true
iris:
  security:
    access-token-expire: 43200      # 过期时间，12小时过期
    refresh-token-expire: 604800    # 7天过期
    auth-count: 5                   # 多少次鉴权失败锁定，0表示不开启
    lock-time: 3600                 # 账号锁定时间(秒)
    ignore-urls:                    # 忽略鉴权的url
      - /actuator/**
      - /v3/api-docs/**
      - /webjars/**
      - /swagger/**
      - /swagger-resources/**
      - /swagger-ui.html
      - /swagger-ui/**
      - /doc.html
      - /upload/**
      - /druid/**
  open-api:
    type: 2 # 1直接保存 2使用MQ异步保存
    auto-start-up: false # Kafka监听是否开启
    cache-time: 604800 # 缓存时间-秒，0不进行缓存，缓存日志可从redis中读取日志保存到表中
  xss:
    enabled: true
    exclude-urls:
      - /oh-generator/**
  # 文件存储相关
  storage:
    enabled: true
    config:
      type: local  # 存储类型：local、aliyun、tencent、qiniu、huawei、minio
      domain: http://localhost:8080
    local.path: /data/图片/upload
# https://docs.spring.io/spring-boot/docs/current/reference/html/application-properties.html
spring:
  servlet:
    multipart:
      max-file-size: 1024MB
      max-request-size: 1024MB
  data:
    redis:
      database: 0
      host: 127.0.0.1
      port: 6379
      #password:
      timeout: 10s  # 连接超时时间
      # 是否开启 SSL
      ssl.enabled: false
  datasource:
    type: com.alibaba.druid.pool.DruidDataSource #数据源的类型
    sys-data-source:
      primary: masterDb # 主数据源或者数据源组,默认 masterDb
      sys-default: sysDb # 系统管理的数据源，用于基础管理的库，如果合并为一个库，则主数据库与系统管理数据库相同，默认 sysDb
    dynamic:
      sysDb: # 系统管理数据源
        driver-class-name: com.mysql.cj.jdbc.Driver
        url: jdbc:mysql://127.0.0.1:3306/oh-sys?useUnicode=true&characterEncoding=UTF-8&serverTimezone=Asia/Shanghai&nullCatalogMeansCurrent=true
        username: root
        password: 123456
        initialSize: 10
        minIdle: 10
        maxActive: 100
        filters: wall,stat
        connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=500
        checkConnection: true # 初始化时是否检查连接，默认false
      masterDb: # 主数据源
        driver-class-name: com.mysql.cj.jdbc.Driver
        url: jdbc:mysql://127.0.0.1:3306/oh-boot?useUnicode=true&characterEncoding=UTF-8&serverTimezone=Asia/Shanghai&nullCatalogMeansCurrent=true
        username: root
        password: 123456
        initialSize: 10
        minIdle: 10
        maxActive: 120
        filters: wall,stat
        connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=1000
        checkConnection: false # 初始化时是否检查连接，默认false
    druid:
      stat-view-servlet:
        enabled: true
        url-pattern: /druid/*
        login-username: admin
        login-password: dB254U9de4c5f4P7Abf # 正式环境需配置复杂密码
      web-stat-filter: # Druid Web统计过滤器配置
        enabled: true # 启用Web统计过滤器
        session-stat-enable: true # 启用会话统计功能
        session-stat-max-count: 1000 # 最大会话统计数量
  kafka:
    bootstrap-servers: 127.0.0.1:9092
    client-id: open-api-flow
    listener:
      ack-mode: MANUAL_IMMEDIATE
      concurrency: 1  # 多任务
      # type: BATCH #开启批量监听
    consumer:
      group-id: oh-group
      max-poll-records: 10
      auto-offset-reset: earliest  # Kafka中没有初始偏移或如果当前偏移在服务器上不再存在时,默认区最新 ，有三个选项 【latest, earliest, none】
      enable-auto-commit: false    # 是否开启自动提交
      auto-commit-interval: 1000   # 自动提交的时间间隔
      key-serializer: org.apache.kafka.common.serialization.StringDeserializer
      value-serializer: org.apache.kafka.common.serialization.StringDeserializer
    producer:
      acks: 1 # 0：producer 不等待 broker 的 ack  1：producer 等待 broker 的 ack，partition 的 leader 落盘成功后返回 ack，如果在 follower 同步成功之前 leader 故障，那么将会丢失数据 -1（all）：producer 等待 broker 的 ack，partition 的 leader 和 follower （ISRL里的follower，不是全部的follower）全部落盘成功后才 返回 ack
      batch-size: 4096
      buffer-memory: 40960000
      client-id: open-api-flow-producer
      compression-type: zstd # 压缩算法
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      retries: 3 # 重复次数
      properties:
        spring.json.add.type.headers: false
        max.request.size: 126951500
        max.block.ms: 30000 # 最大阻塞时间默认60000ms
#rocketmq:
#  name-server: 127.0.0.1:9876 # 服务地址，多个用逗号分开
#  enhance:
#    autoListener: false # 是否启动时监听
#    enabledIsolation: true # 启动隔离，用于激活配置类EnvironmentIsolationConfig,启动后会自动在topic上拼接激活的配置文件，达到自动隔离的效果
#    environment: ${spring.profiles.active} # 隔离环境名称，拼接到topic后,如 topic_dev
#  producer:
#    group: oh_group # 必须指定group
#    send-message-timeout: 3000 # 消息发送超时时长，默认3s
#    retry-times-when-send-failed: 3 # 同步发送消息失败重试次数，默认2
#    retry-times-when-send-async-failed: 3 # 异步发送消息失败重试次数，默认2
#    retryNextServer: false # 是否在内部发送失败时重试另一个broker，默认false
#    maxMessageSize: 4096 # 消息最大长度，默认1024 * 1024 * 4(默认4M)
#    compressMessageBodyThreshold: 4096 # 压缩消息阈值，默认4k(1024 * 4)
# 接口文档
knife4j:
  enable: true  # 开启增强配置
  production: true # 是否开启生产环境保护策略,默认false
  setting:
    enable-footer-custom: true # 是否开启自定义Footer
    footer-custom-content: 2024一起来写代码吧-[王小费](https://gitee.com/whx233)
# 工作流配置 https://docs.camunda.org/manual/latest/user-guide/spring-boot-integration/configuration/
camunda.bpm:
  #enabled: false # Switch to disable the Camunda auto-configuration. Use to exclude Camunda in integration tests.
  process-engine-name: OH工作流   # Name of the process engine
  auto-deployment-enabled: false # 自动部署 resources 下的 bpmn文件
  database:
    type: mysql
    schema-update: true
  generic-properties.properties:
    javaSerializationFormatEnabled: true
    history: full # 历史记录级别设置
    historyTimeToLive: P1000D # 历史数据保存时间 1000天
    # 批量清理运行时间窗口：设置在每天20：00-22：00
    # historyCleanupBatchWindowStartTime: "20:00"
    # historyCleanupBatchWindowEndTime: "22:00"
    # 批量清理运行时间窗口：设置在周日19：00-23：00
    sundayHistoryCleanupBatchWindowStartTime: "19:00"
    sundayHistoryCleanupBatchWindowEndTime: "23:00"
    historyCleanupDegreeOfParallelism: 4 # 用于历史清理的并行作业数
    historyCleanupBatchSize: 100 # 单次批量处理实例数
  admin-user:
    id: admin
    password: daB254U9de4c5f4P7Ab
  # 定时任务
  job-execution:
    enabled: true # 如果设置为 false，则根本不会创建任何 JobExecutor bean。可以用于测试目的
  run:
    # https://docs.camunda.org/manual/latest/user-guide/camunda-bpm-run/#cross-origin-resource-sharing
    cors:
      enabled: true
      allowed-origins: "*"
  filter:
    create: 所有任务

# 日志信息
logging:
  # 字符集设置
  charset:
    file: UTF-8
    console: UTF-8
  level:  # 默认的全局日志级别 TRACE, DEBUG, INFO, WARN, ERROR, FATAL, OFF
    com.iris: INFO
    # root: DEBUG
    org.springframework.web: INFO # web相关的日志级别