spring:
  data:
    redis:
      database: 0
      host: 127.0.0.1
      port: 6379
      #password:
      # 连接超时时间
      timeout: 10s
      # 是否开启 SSL
      ssl:
        enabled: false
  datasource:
    hikari:
      connection-timeout: 30000     # 等待连接池分配链接的最大时长（毫秒），超过这个时长还没有可用的连接则发生 SQLException，默认：30 秒
      minimum-idle: 2               # 最小空闲连接数
      maximum-pool-size: 20         # 最大连接数
      auto-commit: true             # 自动提交
      idle-timeout: 600000          # 连接超时的最大时长（毫秒），超时则被释放（retired），默认：10 分钟
      max-lifetime: 1800000         # 连接的生命时长（毫秒），超时而且没被使用则被释放（retired），默认： 30 分钟
      connection-test-query: SELECT 1
      pool-name: OhHikariCP
      prepStmtCacheSize: 300        # 【mysql】在每个连接中缓存的语句的数量。默认值为保守值25。建议将其设置为250-500之间
      prepStmtCacheSqlLimit: 500    # 缓存的已准备SQL语句的最大长度，默认值是256
      cachePrepStmts: true          # 缓存开关，如果这里设置为false，上面两个参数都不生效
      useServerPrepStmts: true      # 较新版本的 MySQL 支持服务器端准备好的语句
    dynamic:
      #  dynamic主从设置
      primary: master  #设置默认的数据源或者数据源组,默认值即为master
      strict: false  #设置严格模式,默认false不启动. 启动后在未匹配到指定数据源时候回抛出异常,不启动会使用默认数据源.
      datasource:
        master:
          driver-class-name: com.mysql.cj.jdbc.Driver
          url: jdbc:mysql://127.0.0.1:3306/oh-boot?useUnicode=true&characterEncoding=UTF-8&serverTimezone=Asia/Shanghai&nullCatalogMeansCurrent=true
          username: root
          password: 123456
          type: com.zaxxer.hikari.HikariDataSource
          init:
            # 自动运行的建表脚本
            schema: classpath*:db/schema-oh-boot.sql
            # 自动运行的数据脚本
            data: classpath*:db/data-oh-boot.sql
            # 错误是否继续 默认 true
            continue-on-error: true
            # 分隔符 默认 ;
            separator: ;
        extendDB:
          driver-class-name: com.mysql.cj.jdbc.Driver
          url: jdbc:mysql://127.0.0.1:3306/oh-extend?useUnicode=true&characterEncoding=UTF-8&serverTimezone=Asia/Shanghai&nullCatalogMeansCurrent=true
          username: root
          password: 123456
          type: com.zaxxer.hikari.HikariDataSource
          init:
            # 自动运行的建表脚本
            schema: classpath*:db/schema-oh-extend.sql
            # 自动运行的数据脚本
            data: classpath*:db/data-oh-extend.sql
            # 错误是否继续 默认 true
            continue-on-error: true
            # 分隔符 默认 ;
            separator: ;
  kafka:
    bootstrap-servers: 127.0.0.1:9092
    client-id: dc-device-flow-analyze
    consumer:
      group-id: oh-group
      max-poll-records: 10
      #Kafka中没有初始偏移或如果当前偏移在服务器上不再存在时,默认区最新 ，有三个选项 【latest, earliest, none】
      auto-offset-reset: earliest
      #是否开启自动提交
      enable-auto-commit: false
      #自动提交的时间间隔
      auto-commit-interval: 1000
    producer:
      # 0：producer 不等待 broker 的 ack
      # 1：producer 等待 broker 的 ack，partition 的 leader 落盘成功后返回 ack，如果在 follower 同步成功之前 leader 故障，那么将会丢失数据
      # -1（all）：producer 等待 broker 的 ack，partition 的 leader 和 follower （ISRL里的follower，不是全部的follower）全部落盘成功后才 返回 ack
      acks: 1
      batch-size: 4096
      buffer-memory: 40960000
      client-id: dc-device-flow-analyze-producer
      # 压缩算法
      compression-type: zstd
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      # value-serializer: org.apache.kafka.common.serialization.StringSerializer
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      retries: 3
      properties:
        spring.json.add.type.headers: false
        max.request.size: 126951500
    listener:
      ack-mode: MANUAL_IMMEDIATE
      concurrency: 1  #推荐设置为topic的分区数
      type: BATCH #开启批量监听
# 接口文档
knife4j:
  # 开启增强配置
  enable: true
  # 是否生产环境，生产环境屏蔽接口文档，开发环境需显示接口文档
  production: true
  setting:
    custom-code: 500
    enable-footer-custom: false
# 工作流配置 https://docs.camunda.org/manual/latest/user-guide/spring-boot-integration/configuration/
camunda.bpm:
  #enabled: false # Switch to disable the Camunda auto-configuration. Use to exclude Camunda in integration tests.
  process-engine-name: OH工作流 # Name of the process engine
  auto-deployment-enabled: false # 自动部署 resources 下的 bpmn文件
  database:
    type: mysql
    schema-update: true
  generic-properties.properties:
    javaSerializationFormatEnabled: true
    historyTimeToLive: P365D
  admin-user:
    id: admin
    password: 123456
  # 定时任务
  job-execution:
    enabled: false # 如果设置为 false，则根本不会创建任何 JobExecutor bean。可以用于测试目的
  run:
    # https://docs.camunda.org/manual/latest/user-guide/camunda-bpm-run/#cross-origin-resource-sharing
    cors:
      enabled: true
      allowed-origins: "*"
  filter:
    create: 所有任务