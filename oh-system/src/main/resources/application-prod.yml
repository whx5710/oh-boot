spring:
  data:
    redis:
      database: 1
      host: 192.168.239.131
      port: 6379
      #password:
      #timeout: 6000ms  # 连接超时时长（毫秒）
  datasource:
    hikari:
      connection-timeout: 30000     # 等待连接池分配链接的最大时长（毫秒），超过这个时长还没有可用的连接则发生 SQLException，默认：30 秒
      minimum-idle: 2               # 最小空闲连接数
      maximum-pool-size: 20         # 最大连接数
      auto-commit: true             # 自动提交
      idle-timeout: 600000          # 连接超时的最大时长（毫秒），超时则被释放（retired），默认：10 分钟
      max-lifetime: 1800000         # 连接的生命时长（毫秒），超时而且没被使用则被释放（retired），默认： 30 分钟
      connection-test-query: SELECT 1
      pool-name: OhHikariCP
    dynamic:
      #  dynamic主从设置
      primary: master  #设置默认的数据源或者数据源组,默认值即为master
      strict: false  #设置严格模式,默认false不启动. 启动后在未匹配到指定数据源时候回抛出异常,不启动会使用默认数据源.
      datasource:
        master:
          driver-class-name: com.mysql.cj.jdbc.Driver
          url: jdbc:mysql://192.168.239.131:3306/oh-boot?useUnicode=true&characterEncoding=UTF-8&serverTimezone=Asia/Shanghai&nullCatalogMeansCurrent=true
          username: root
          password: 123456
          type: com.zaxxer.hikari.HikariDataSource
          init:
            # 自动运行的建表脚本
            schema: classpath*:db/schema-oh-boot.sql
            # 自动运行的数据脚本
            data: classpath*:db/data-oh-boot.sql
            # 错误是否继续 默认 true
            continue-on-error: true
            # 分隔符 默认 ;
            separator: ;
        extendDB:
          driver-class-name: com.mysql.cj.jdbc.Driver
          url: jdbc:mysql://192.168.239.131:3306/oh-extend?useUnicode=true&characterEncoding=UTF-8&serverTimezone=Asia/Shanghai&nullCatalogMeansCurrent=true
          username: root
          password: 123456
          type: com.zaxxer.hikari.HikariDataSource
          init:
            # 自动运行的建表脚本
            schema: classpath*:db/schema-oh-extend.sql
            # 自动运行的数据脚本
            data: classpath*:db/data-oh-extend.sql
            # 错误是否继续 默认 true
            continue-on-error: true
            # 分隔符 默认 ;
            separator: ;
  kafka:
    bootstrap-servers: 192.168.239.131:9092
    client-id: dc-device-flow-analyze
    consumer:
      group-id: oh-group
      max-poll-records: 10
      #Kafka中没有初始偏移或如果当前偏移在服务器上不再存在时,默认区最新 ，有三个选项 【latest, earliest, none】
      auto-offset-reset: earliest
      #是否开启自动提交
      enable-auto-commit: false
      #自动提交的时间间隔
      auto-commit-interval: 1000
    producer:
      # 0：producer 不等待 broker 的 ack
      # 1：producer 等待 broker 的 ack，partition 的 leader 落盘成功后返回 ack，如果在 follower 同步成功之前 leader 故障，那么将会丢失数据
      # -1（all）：producer 等待 broker 的 ack，partition 的 leader 和 follower （ISRL里的follower，不是全部的follower）全部落盘成功后才 返回 ack
      acks: 1
      batch-size: 4096
      buffer-memory: 40960000
      client-id: dc-device-flow-analyze-producer
      # 压缩算法
      compression-type: zstd
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      # value-serializer: org.apache.kafka.common.serialization.StringSerializer
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      retries: 3
      properties:
        spring.json.add.type.headers: false
        max.request.size: 126951500
    listener:
      ack-mode: MANUAL_IMMEDIATE
      concurrency: 1  #推荐设置为topic的分区数
      type: BATCH #开启批量监听

# 工作流
camunda.bpm:
  generic-properties.properties:
    javaSerializationFormatEnabled: true
  admin-user:
    id: admin
    password: 123456
  run:
    # https://docs.camunda.org/manual/latest/user-guide/camunda-bpm-run/#cross-origin-resource-sharing
    cors:
      enabled: true
      allowed-origins: "*"
  filter:
    create: 所有任务